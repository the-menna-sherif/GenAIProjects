1- Gradio GUI up but throwing error (text-summarizer.py) ----->>> Terminal shows below error:
Your max_length is set to 142, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)
Traceback (most recent call last):
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\gradio\queueing.py", line 763, in process_events
    response = await route_utils.call_process_api(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<5 lines>...
    )
    ^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\gradio\route_utils.py", line 354, in call_process_api
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<11 lines>...
    )
    ^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\gradio\blocks.py", line 2125, in process_api
    result = await self.call_function(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
    )
    ^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\gradio\blocks.py", line 1607, in call_function
    prediction = await anyio.to_thread.run_sync(  # type: ignore
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        fn, *processed_input, limiter=self.limiter
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\anyio\to_thread.py", line 61, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2525, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 986, in run
    result = context.run(func, *args)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\gradio\utils.py", line 1066, in wrapper
    response = f(*args, **kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\text-summarizer.py", line 11, in summarize
    output = text_summary(text)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\text2text_generation.py", line 303, in __call__
    return super().__call__(*args, **kwargs)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\text2text_generation.py", line 191, in __call__
    result = super().__call__(*args, **kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\base.py", line 1467, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\base.py", line 1474, in run_single
    model_outputs = self.forward(model_inputs, **forward_params)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\base.py", line 1374, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\pipelines\text2text_generation.py", line 220, in _forward
    output_ids = self.model.generate(**model_inputs, **generate_kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\generation\utils.py", line 2388, in generate
    self._validate_model_kwargs(model_kwargs.copy())
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\transformers\generation\utils.py", line 1599, in _validate_model_kwargs
    raise ValueError(
    ...<2 lines>...
    )
ValueError: The following `model_kwargs` are not used by the model: ['local_files_only'] (note: typos in the generate arguments will also show up in this list)

Breakdown: 
Checking the pipeline & transformers documentation
https://huggingface.co/docs/transformers/en/main_classes/pipelines
- local_files_only is not an argument especially when passed to model.generate()
- choosing to modify the code to call the model > tokenizer > pipeline. benefits:
1) increase control over: how the model is loaded, where it’s loaded, precision, caching behavior, torch_dtype, device_map, quantization, offline mode, etc.
2) increased debugging 
Rule of Thumb: "If your code lives longer than a notebook cell, don’t rely on pipeline defaults."
Fixed by adding the code for model & tokenizer prior to pipeline


2- youtube-summarizer.py throwing below stacktrace:
Traceback (most recent call last):
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connection.py", line 796, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
        sock=sock,
    ...<14 lines>...
        assert_fingerprint=self.assert_fingerprint,
    )
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connection.py", line 975, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
        sock=sock,
    ...<8 lines>...
        tls_in_tls=tls_in_tls,
    )
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\util\ssl_.py", line 483, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\util\ssl_.py", line 527, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\msherif\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 455, in wrap_socket
    return self.sslsocket_class._create(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        sock=sock,
        ^^^^^^^^^^
    ...<5 lines>...
        session=session
        ^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\msherif\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1076, in _create
    self.do_handshake()
    ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\msherif\AppData\Local\Programs\Python\Python313\Lib\ssl.py", line 1372, in do_handshake
    self._sslobj.do_handshake()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.youtube.com', port=443): Max retries exceeded with url: /watch?v=dQw4w9WgXcQ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\youtube-summarizer.py", line 31, in <module>
    print(get_transcript_from_url(url))
          ~~~~~~~~~~~~~~~~~~~~~~~^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\youtube-summarizer.py", line 23, in get_transcript_from_url
    transcript = api.fetch(video_id)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_api.py", line 71, in fetch
    self.list(video_id)
    ~~~~~~~~~^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_api.py", line 127, in list
    return self._fetcher.fetch(video_id)
           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_transcripts.py", line 356, in fetch
    self._fetch_captions_json(video_id),
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_transcripts.py", line 361, in _fetch_captions_json
    html = self._fetch_video_html(video_id)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_transcripts.py", line 433, in _fetch_video_html
    html = self._fetch_html(video_id)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\youtube_transcript_api\_transcripts.py", line 442, in _fetch_html
    response = self._http_client.get(WATCH_URL.format(video_id=video_id))
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\msherif\PycharmProjects\GenAIProjects\text-classification\venv\Lib\site-packages\requests\adapters.py", line 675, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='www.youtube.com', port=443): Max retries exceeded with url: /watch?v=dQw4w9WgXcQ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)')))

Breakdown:
> curl https://www.youtube.com
Returned 200 OK
> pip install --upgrade youtube-transcript-api
On the latest version

Definitely env issue. Possibly cuz corporate proxy/ wifi.
